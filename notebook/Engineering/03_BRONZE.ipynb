{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95056581-2667-46c1-a5b0-e79c73bf6994",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "Wrong FS: s3a://ingestion/, expected: file:///",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m fs \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39morg\u001b[38;5;241m.\u001b[39mapache\u001b[38;5;241m.\u001b[39mhadoop\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39mFileSystem\u001b[38;5;241m.\u001b[39mget(spark\u001b[38;5;241m.\u001b[39m_jsc\u001b[38;5;241m.\u001b[39mhadoopConfiguration())\n\u001b[1;32m     30\u001b[0m path \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39morg\u001b[38;5;241m.\u001b[39mapache\u001b[38;5;241m.\u001b[39mhadoop\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39mPath(base_path)\n\u001b[0;32m---> 31\u001b[0m files \u001b[38;5;241m=\u001b[39m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistStatus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Extrair nomes dos arquivos CSV\u001b[39;00m\n\u001b[1;32m     34\u001b[0m csv_files \u001b[38;5;241m=\u001b[39m [f\u001b[38;5;241m.\u001b[39mgetPath()\u001b[38;5;241m.\u001b[39mgetName() \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mgetPath()\u001b[38;5;241m.\u001b[39mgetName()\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: Wrong FS: s3a://ingestion/, expected: file:///"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "import re\n",
    "\n",
    "# Caminho base do bucket MinIO\n",
    "base_path = \"s3a://ingestion/\"\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('dataincode') \\\n",
    "    .config(\"spark.jars\", \"/opt/spark/jars/iceberg-spark-runtime-3.5_2.12-1.6.0.jar\") \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "    .config(\"spark.sql.catalog.local\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog.type\", \"hive\") \\\n",
    "    .config(\"spark.sql.catalog.local.warehouse\", \"s3a://datalake/iceberg\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://192.168.0.202:9000\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minio\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minio123\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# Ajuste para reduzir o n√≠vel de log\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "\n",
    "# Lista todos os arquivos no bucket (via Hadoop API)\n",
    "fs = spark._jvm.org.apache.hadoop.fs.FileSystem.get(spark._jsc.hadoopConfiguration())\n",
    "path = spark._jvm.org.apache.hadoop.fs.Path(base_path)\n",
    "files = fs.listStatus(path)\n",
    "\n",
    "# Extrair nomes dos arquivos CSV\n",
    "csv_files = [f.getPath().getName() for f in files if f.getPath().getName().endswith(\".csv\")]\n",
    "\n",
    "# Agrupar por prefixo antes do √∫ltimo underscore \"_\"\n",
    "from collections import defaultdict\n",
    "prefix_groups = defaultdict(list)\n",
    "\n",
    "for file in csv_files:\n",
    "    match = re.match(r\"(.+?)_\\d+\\.csv\", file)\n",
    "    if match:\n",
    "        prefix = match.group(1)\n",
    "    else:\n",
    "        prefix = file.replace(\".csv\", \"\")  # arquivos √∫nicos\n",
    "\n",
    "    prefix_groups[prefix].append(file)\n",
    "\n",
    "# Para cada prefixo, carregar os arquivos e criar tabela Iceberg\n",
    "for prefix, files in prefix_groups.items():\n",
    "    print(f\"Processando prefixo: {prefix}\")\n",
    "\n",
    "    file_paths = [f\"s3a://ingestion/{file}\" for file in files]\n",
    "\n",
    "    # Carregar os CSVs\n",
    "    df = spark.read.option(\"header\", \"true\").csv(file_paths)\n",
    "\n",
    "    # Inferir schema uma vez (ou printar se quiser criar CREATE TABLE manual)\n",
    "    df.printSchema()\n",
    "\n",
    "    # Criar tabela se n√£o existir (ajustar tipos conforme seu schema real)\n",
    "    # Aqui usamos STRING como exemplo para todos os campos\n",
    "    cols = \", \".join([f\"{field.name} STRING\" for field in df.schema.fields])\n",
    "\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS local.bronze.{prefix} (\n",
    "            {cols}\n",
    "        )\n",
    "        USING iceberg\n",
    "    \"\"\")\n",
    "\n",
    "    # Inserir dados no modo append\n",
    "    df.writeTo(f\"local.bronze.{prefix}\").append()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43b15504-98fd-4544-81ab-37459140fc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EndPoint http://minio:9000 | access minio | key minio123 \n"
     ]
    },
    {
     "ename": "IllegalArgumentException",
     "evalue": "Wrong FS: s3a://ingestion/, expected: file:///",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m fs \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39morg\u001b[38;5;241m.\u001b[39mapache\u001b[38;5;241m.\u001b[39mhadoop\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39mFileSystem\u001b[38;5;241m.\u001b[39mget(spark\u001b[38;5;241m.\u001b[39m_jsc\u001b[38;5;241m.\u001b[39mhadoopConfiguration())\n\u001b[1;32m     40\u001b[0m path \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39morg\u001b[38;5;241m.\u001b[39mapache\u001b[38;5;241m.\u001b[39mhadoop\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39mPath(base_path)\n\u001b[0;32m---> 41\u001b[0m files \u001b[38;5;241m=\u001b[39m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistStatus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Filtrar arquivos CSV\u001b[39;00m\n\u001b[1;32m     44\u001b[0m csv_files \u001b[38;5;241m=\u001b[39m [f\u001b[38;5;241m.\u001b[39mgetPath()\u001b[38;5;241m.\u001b[39mgetName() \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mgetPath()\u001b[38;5;241m.\u001b[39mgetName()\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: Wrong FS: s3a://ingestion/, expected: file:///"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from collections import defaultdict\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Carrega vari√°veis de ambiente\n",
    "load_dotenv()\n",
    "s3_endpoint = os.getenv(\"S3_ENDPOINT\")\n",
    "s3_access_key = os.getenv(\"S3_ACCESS_KEY\")\n",
    "s3_secret_key = os.getenv(\"S3_SECRET_KEY\")\n",
    "\n",
    "print(f\"EndPoint {s3_endpoint} | access {s3_access_key} | key {s3_secret_key} \")\n",
    "\n",
    "# Caminho base do bucket MinIO\n",
    "base_path = \"s3a://ingestion/\"\n",
    "\n",
    "# SparkSession com suporte a Iceberg + MinIO\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"dataincode\") \\\n",
    "    .config(\"spark.jars\", \"/opt/spark/jars/iceberg-spark-runtime-3.5_2.12-1.6.0.jar\") \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "    .config(\"spark.sql.catalog.local\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.local.type\", \"hadoop\") \\\n",
    "    .config(\"spark.sql.catalog.local.warehouse\", \"s3a://datalake/iceberg\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", s3_endpoint) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", s3_access_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", s3_secret_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.AbstractFileSystem.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3A\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# Listar arquivos no bucket\n",
    "fs = spark._jvm.org.apache.hadoop.fs.FileSystem.get(spark._jsc.hadoopConfiguration())\n",
    "path = spark._jvm.org.apache.hadoop.fs.Path(base_path)\n",
    "files = fs.listStatus(path)\n",
    "\n",
    "# Filtrar arquivos CSV\n",
    "csv_files = [f.getPath().getName() for f in files if f.getPath().getName().endswith(\".csv\")]\n",
    "\n",
    "# Agrupar por prefixo\n",
    "prefix_groups = defaultdict(list)\n",
    "for file in csv_files:\n",
    "    match = re.match(r\"(.+?)_\\d+\\.csv\", file)\n",
    "    prefix = match.group(1) if match else file.replace(\".csv\", \"\")\n",
    "    prefix_groups[prefix].append(file)\n",
    "\n",
    "# Processar cada grupo\n",
    "for prefix, files in prefix_groups.items():\n",
    "    print(f\"üîß Processando prefixo: {prefix}\")\n",
    "    \n",
    "    file_paths = [f\"s3a://ingestion/{file}\" for file in files]\n",
    "    df = spark.read.option(\"header\", \"true\").csv(file_paths)\n",
    "    \n",
    "    # Printar o schema inferido\n",
    "    df.printSchema()\n",
    "    \n",
    "    # Montar os campos para CREATE TABLE\n",
    "    cols = \", \".join([f\"{field.name} STRING\" for field in df.schema.fields])\n",
    "    \n",
    "    # Criar tabela Iceberg se n√£o existir\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS local.bronze.{prefix} (\n",
    "            {cols}\n",
    "        )\n",
    "        USING iceberg\n",
    "    \"\"\")\n",
    "    \n",
    "    # Inserir os dados (append)\n",
    "    df.writeTo(f\"local.bronze.{prefix}\").append()\n",
    "    print(f\"‚úÖ Tabela 'local.bronze.{prefix}' criada e populada!\")\n",
    "\n",
    "print(\"üöÄ Todas as tabelas foram processadas com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13684157-f886-4015-9335-2dbefec9dbc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1b37ff3-ce7e-4fbf-be8e-4d7f0c4d3e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîê Endpoint: http://minio:9000 | Access Key: minio\n",
      "\n",
      "üîß Processando prefixo: clientes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- nome: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- data_cadastro: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tabela 'local.bronze.clientes' criada/populada com sucesso!\n",
      "\n",
      "üîß Processando prefixo: pedido\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- cliente_id: string (nullable = true)\n",
      " |-- data_pedido: string (nullable = true)\n",
      " |-- valor_total: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tabela 'local.bronze.pedido' criada/populada com sucesso!\n",
      "\n",
      "üîß Processando prefixo: stgPedidos\n",
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- ikey: string (nullable = true)\n",
      " |-- idate: string (nullable = true)\n",
      " |-- ihour: string (nullable = true)\n",
      " |-- itype: string (nullable = true)\n",
      " |-- chave: string (nullable = true)\n",
      " |-- classe: string (nullable = true)\n",
      " |-- chcriacao: string (nullable = true)\n",
      " |-- chpedbaixa: string (nullable = true)\n",
      " |-- chdevoluc: string (nullable = true)\n",
      " |-- chfatura: string (nullable = true)\n",
      " |-- baixado: string (nullable = true)\n",
      " |-- recurso: string (nullable = true)\n",
      " |-- locentrega: string (nullable = true)\n",
      " |-- locescritu: string (nullable = true)\n",
      " |-- pessoa: string (nullable = true)\n",
      " |-- emissao: string (nullable = true)\n",
      " |-- tipo: string (nullable = true)\n",
      " |-- seriesubs: string (nullable = true)\n",
      " |-- numero: string (nullable = true)\n",
      " |-- nucleo: string (nullable = true)\n",
      " |-- movimentac: string (nullable = true)\n",
      " |-- emissaomov: string (nullable = true)\n",
      " |-- unitario: string (nullable = true)\n",
      " |-- quantidade: string (nullable = true)\n",
      " |-- pedbaixado: string (nullable = true)\n",
      " |-- item: string (nullable = true)\n",
      " |-- ipi: string (nullable = true)\n",
      " |-- total: string (nullable = true)\n",
      " |-- programaca: string (nullable = true)\n",
      " |-- tolermais: string (nullable = true)\n",
      " |-- tolermenos: string (nullable = true)\n",
      " |-- descitem: string (nullable = true)\n",
      " |-- desconto: string (nullable = true)\n",
      " |-- icms: string (nullable = true)\n",
      " |-- iss: string (nullable = true)\n",
      " |-- ir: string (nullable = true)\n",
      " |-- transporta: string (nullable = true)\n",
      " |-- tipofrete: string (nullable = true)\n",
      " |-- volespecie: string (nullable = true)\n",
      " |-- volmarca: string (nullable = true)\n",
      " |-- volnumero: string (nullable = true)\n",
      " |-- representa: string (nullable = true)\n",
      " |-- refreprese: string (nullable = true)\n",
      " |-- unidmedfat: string (nullable = true)\n",
      " |-- quantidfat: string (nullable = true)\n",
      " |-- chacessor0: string (nullable = true)\n",
      " |-- chacessor1: string (nullable = true)\n",
      " |-- chacessor2: string (nullable = true)\n",
      " |-- chacessor3: string (nullable = true)\n",
      " |-- aprovacao: string (nullable = true)\n",
      " |-- aprovador: string (nullable = true)\n",
      " |-- cancelamen: string (nullable = true)\n",
      " |-- cancelador: string (nullable = true)\n",
      " |-- frete: string (nullable = true)\n",
      " |-- seguro: string (nullable = true)\n",
      " |-- acrescimo: string (nullable = true)\n",
      " |-- comissper: string (nullable = true)\n",
      " |-- comissao: string (nullable = true)\n",
      " |-- ipibc: string (nullable = true)\n",
      " |-- ipialiq: string (nullable = true)\n",
      " |-- ipicredeb: string (nullable = true)\n",
      " |-- ipiestorn: string (nullable = true)\n",
      " |-- ipiisento: string (nullable = true)\n",
      " |-- icmsbc: string (nullable = true)\n",
      " |-- icmsaliq: string (nullable = true)\n",
      " |-- icmsdifal: string (nullable = true)\n",
      " |-- icmsestda: string (nullable = true)\n",
      " |-- icmsst: string (nullable = true)\n",
      " |-- icmsstbc: string (nullable = true)\n",
      " |-- icmsstal: string (nullable = true)\n",
      " |-- icmscread: string (nullable = true)\n",
      " |-- icmscrede: string (nullable = true)\n",
      " |-- icmsisent: string (nullable = true)\n",
      " |-- issbc: string (nullable = true)\n",
      " |-- issaliq: string (nullable = true)\n",
      " |-- irbc: string (nullable = true)\n",
      " |-- iraliq: string (nullable = true)\n",
      " |-- irretfont: string (nullable = true)\n",
      " |-- iibc: string (nullable = true)\n",
      " |-- iialiq: string (nullable = true)\n",
      " |-- ii: string (nullable = true)\n",
      " |-- cofins: string (nullable = true)\n",
      " |-- pis: string (nullable = true)\n",
      " |-- obsfiscal: string (nullable = true)\n",
      " |-- custocont: string (nullable = true)\n",
      " |-- volqde: string (nullable = true)\n",
      " |-- volpesbru: string (nullable = true)\n",
      " |-- volpesliq: string (nullable = true)\n",
      " |-- acessori0: string (nullable = true)\n",
      " |-- acessori1: string (nullable = true)\n",
      " |-- acessori2: string (nullable = true)\n",
      " |-- acessori3: string (nullable = true)\n",
      " |-- selonumero: string (nullable = true)\n",
      " |-- taxaoperac: string (nullable = true)\n",
      " |-- diascompen: string (nullable = true)\n",
      " |-- cpmfperc: string (nullable = true)\n",
      " |-- iofaliq: string (nullable = true)\n",
      " |-- advalaliq: string (nullable = true)\n",
      " |-- observacao: string (nullable = true)\n",
      " |-- obscabecal: string (nullable = true)\n",
      " |-- cfo: string (nullable = true)\n",
      " |-- seloserie: string (nullable = true)\n",
      " |-- baixaautom: string (nullable = true)\n",
      " |-- comissperi: string (nullable = true)\n",
      " |-- comissaoi: string (nullable = true)\n",
      " |-- cfoi: string (nullable = true)\n",
      " |-- ipibci: string (nullable = true)\n",
      " |-- ipialiqi: string (nullable = true)\n",
      " |-- ipicredebi: string (nullable = true)\n",
      " |-- ipiestorni: string (nullable = true)\n",
      " |-- ipiisentoi: string (nullable = true)\n",
      " |-- icmsbci: string (nullable = true)\n",
      " |-- icmsaliqi: string (nullable = true)\n",
      " |-- icmsdifali: string (nullable = true)\n",
      " |-- icmsstbci: string (nullable = true)\n",
      " |-- icmsstali: string (nullable = true)\n",
      " |-- icmscreadi: string (nullable = true)\n",
      " |-- icmscredei: string (nullable = true)\n",
      " |-- icmsisenti: string (nullable = true)\n",
      " |-- issbci: string (nullable = true)\n",
      " |-- issaliqi: string (nullable = true)\n",
      " |-- irbci: string (nullable = true)\n",
      " |-- iraliqi: string (nullable = true)\n",
      " |-- irretfonti: string (nullable = true)\n",
      " |-- iibci: string (nullable = true)\n",
      " |-- iialiqi: string (nullable = true)\n",
      " |-- cofinsi: string (nullable = true)\n",
      " |-- pisi: string (nullable = true)\n",
      " |-- obsfiscali: string (nullable = true)\n",
      " |-- volqdei: string (nullable = true)\n",
      " |-- volpesbrui: string (nullable = true)\n",
      " |-- volpesliqi: string (nullable = true)\n",
      " |-- versao: string (nullable = true)\n",
      " |-- issretfoni: string (nullable = true)\n",
      " |-- issretfon: string (nullable = true)\n",
      " |-- inssbc: string (nullable = true)\n",
      " |-- inssbci: string (nullable = true)\n",
      " |-- inssaliq: string (nullable = true)\n",
      " |-- inssaliqi: string (nullable = true)\n",
      " |-- inss: string (nullable = true)\n",
      " |-- inssretfo: string (nullable = true)\n",
      " |-- inssretfoi: string (nullable = true)\n",
      " |-- moeda: string (nullable = true)\n",
      " |-- moedavalor: string (nullable = true)\n",
      " |-- chacessor4: string (nullable = true)\n",
      " |-- chacessor5: string (nullable = true)\n",
      " |-- chacessor6: string (nullable = true)\n",
      " |-- chacessor7: string (nullable = true)\n",
      " |-- chacessor8: string (nullable = true)\n",
      " |-- chacessor9: string (nullable = true)\n",
      " |-- acessori4: string (nullable = true)\n",
      " |-- acessori5: string (nullable = true)\n",
      " |-- acessori6: string (nullable = true)\n",
      " |-- acessori7: string (nullable = true)\n",
      " |-- acessori8: string (nullable = true)\n",
      " |-- acessori9: string (nullable = true)\n",
      " |-- indice: string (nullable = true)\n",
      " |-- indicemes: string (nullable = true)\n",
      " |-- placas: string (nullable = true)\n",
      " |-- pedido: string (nullable = true)\n",
      " |-- irmao: string (nullable = true)\n",
      " |-- liberador: string (nullable = true)\n",
      " |-- liberacao: string (nullable = true)\n",
      " |-- pisst: string (nullable = true)\n",
      " |-- pissti: string (nullable = true)\n",
      " |-- cofinsst: string (nullable = true)\n",
      " |-- cofinssti: string (nullable = true)\n",
      " |-- descperc: string (nullable = true)\n",
      " |-- desciperc: string (nullable = true)\n",
      " |-- desciperci: string (nullable = true)\n",
      " |-- aidf: string (nullable = true)\n",
      " |-- ordemequip: string (nullable = true)\n",
      " |-- ordemcf: string (nullable = true)\n",
      " |-- disponivel: string (nullable = true)\n",
      " |-- motivodevo: string (nullable = true)\n",
      " |-- lote: string (nullable = true)\n",
      " |-- emissaomovh: string (nullable = true)\n",
      " |-- iniciouso: string (nullable = true)\n",
      " |-- iniciousoentidade: string (nullable = true)\n",
      " |-- iniciousoh: string (nullable = true)\n",
      " |-- entnome: string (nullable = true)\n",
      " |-- entfone: string (nullable = true)\n",
      " |-- entendereco: string (nullable = true)\n",
      " |-- entbairro: string (nullable = true)\n",
      " |-- entzonacidade: string (nullable = true)\n",
      " |-- entcidade: string (nullable = true)\n",
      " |-- entuf: string (nullable = true)\n",
      " |-- entcep: string (nullable = true)\n",
      " |-- entpontorefer: string (nullable = true)\n",
      " |-- entrega: string (nullable = true)\n",
      " |-- entpagguia: string (nullable = true)\n",
      " |-- descpercsuframa: string (nullable = true)\n",
      " |-- descsuframa: string (nullable = true)\n",
      " |-- renumero: string (nullable = true)\n",
      " |-- redespacho: string (nullable = true)\n",
      " |-- reembarque: string (nullable = true)\n",
      " |-- seloqde: string (nullable = true)\n",
      " |-- numeroseq: string (nullable = true)\n",
      " |-- parc1comipi: string (nullable = true)\n",
      " |-- totaldanota: string (nullable = true)\n",
      " |-- chcotacao: string (nullable = true)\n",
      " |-- cotacao: string (nullable = true)\n",
      " |-- cotvigeini: string (nullable = true)\n",
      " |-- cotvigefin: string (nullable = true)\n",
      " |-- jurop: string (nullable = true)\n",
      " |-- custoliq: string (nullable = true)\n",
      " |-- condpgto: string (nullable = true)\n",
      " |-- inssretemp: string (nullable = true)\n",
      " |-- formulario: string (nullable = true)\n",
      " |-- recursoagrupa: string (nullable = true)\n",
      " |-- unificadoragrupa: string (nullable = true)\n",
      " |-- entcomplemento: string (nullable = true)\n",
      " |-- entlocalidade: string (nullable = true)\n",
      " |-- entlogradouro: string (nullable = true)\n",
      " |-- entnumero: string (nullable = true)\n",
      " |-- entpais: string (nullable = true)\n",
      " |-- entsublocalidade: string (nullable = true)\n",
      " |-- enttipologradouro: string (nullable = true)\n",
      " |-- pessoacontrato: string (nullable = true)\n",
      " |-- icmsantec: string (nullable = true)\n",
      " |-- codclienergia: string (nullable = true)\n",
      " |-- cofinsrefo: string (nullable = true)\n",
      " |-- csll: string (nullable = true)\n",
      " |-- cslli: string (nullable = true)\n",
      " |-- cofinsrefoi: string (nullable = true)\n",
      " |-- csllrefoi: string (nullable = true)\n",
      " |-- pisrefoi: string (nullable = true)\n",
      " |-- ordem: string (nullable = true)\n",
      " |-- consumofat: string (nullable = true)\n",
      " |-- totprinc: string (nullable = true)\n",
      " |-- totprincajust: string (nullable = true)\n",
      " |-- totrecfin: string (nullable = true)\n",
      " |-- totrecfinajust: string (nullable = true)\n",
      " |-- inicioatraso: string (nullable = true)\n",
      " |-- iinformedfields: string (nullable = true)\n",
      " |-- chorigem: string (nullable = true)\n",
      " |-- ativolote: string (nullable = true)\n",
      " |-- estabeleci: string (nullable = true)\n",
      " |-- moedatabcotacao: string (nullable = true)\n",
      " |-- scompetencia: string (nullable = true)\n",
      " |-- svincproduto: string (nullable = true)\n",
      " |-- sproxunitario: string (nullable = true)\n",
      " |-- smotivoreajuste: string (nullable = true)\n",
      " |-- movdisposcomissao: string (nullable = true)\n",
      " |-- comissaobc: string (nullable = true)\n",
      " |-- icmscodtrib: string (nullable = true)\n",
      " |-- icmscodtribi: string (nullable = true)\n",
      " |-- procedenci: string (nullable = true)\n",
      " |-- procedencii: string (nullable = true)\n",
      " |-- entradareneg: string (nullable = true)\n",
      " |-- adicionalnegociado: string (nullable = true)\n",
      " |-- tipoentrega: string (nullable = true)\n",
      " |-- solicitacao: string (nullable = true)\n",
      " |-- ecotacao: string (nullable = true)\n",
      " |-- crpedido: string (nullable = true)\n",
      " |-- chmovdispo: string (nullable = true)\n",
      " |-- programacadias: string (nullable = true)\n",
      " |-- sreferenvencimento: string (nullable = true)\n",
      " |-- comprador: string (nullable = true)\n",
      " |-- arquivosanexados: string (nullable = true)\n",
      " |-- msproject: string (nullable = true)\n",
      " |-- simula: string (nullable = true)\n",
      " |-- tabfator: string (nullable = true)\n",
      " |-- programacah: string (nullable = true)\n",
      " |-- eventobloqueio: string (nullable = true)\n",
      " |-- chpedbaixatemp: string (nullable = true)\n",
      " |-- customat: string (nullable = true)\n",
      " |-- customod: string (nullable = true)\n",
      " |-- custoggf: string (nullable = true)\n",
      " |-- icmsoutros: string (nullable = true)\n",
      " |-- ipioutros: string (nullable = true)\n",
      " |-- sglosado: string (nullable = true)\n",
      " |-- staxaadmin: string (nullable = true)\n",
      " |-- descnegfin: string (nullable = true)\n",
      " |-- ajustefino: string (nullable = true)\n",
      " |-- validade: string (nullable = true)\n",
      " |-- eventocriacao: string (nullable = true)\n",
      " |-- ordemcnf: string (nullable = true)\n",
      " |-- tipooperacao: string (nullable = true)\n",
      " |-- iof: string (nullable = true)\n",
      " |-- usuario: string (nullable = true)\n",
      " |-- observacaohash: string (nullable = true)\n",
      " |-- sinssressarcido: string (nullable = true)\n",
      " |-- fatorpis: string (nullable = true)\n",
      " |-- fatorcofins: string (nullable = true)\n",
      " |-- fatorcsll: string (nullable = true)\n",
      " |-- fatorir: string (nullable = true)\n",
      " |-- fatorinss: string (nullable = true)\n",
      " |-- fatoriss: string (nullable = true)\n",
      " |-- fatoricms: string (nullable = true)\n",
      " |-- fatoripi: string (nullable = true)\n",
      " |-- pisaliq: string (nullable = true)\n",
      " |-- pisfator: string (nullable = true)\n",
      " |-- cofinsfator: string (nullable = true)\n",
      " |-- csllfator: string (nullable = true)\n",
      " |-- irfator: string (nullable = true)\n",
      " |-- inssfator: string (nullable = true)\n",
      " |-- issfator: string (nullable = true)\n",
      " |-- icmsfator: string (nullable = true)\n",
      " |-- icmsstfator: string (nullable = true)\n",
      " |-- iifator: string (nullable = true)\n",
      " |-- ipifator: string (nullable = true)\n",
      " |-- icmsstdevido: string (nullable = true)\n",
      " |-- csllaliq: string (nullable = true)\n",
      " |-- csllbc: string (nullable = true)\n",
      " |-- corretor: string (nullable = true)\n",
      " |-- datahorachave: string (nullable = true)\n",
      " |-- basecorrecao: string (nullable = true)\n",
      " |-- totjuro: string (nullable = true)\n",
      " |-- totmulta: string (nullable = true)\n",
      " |-- totjuroajust: string (nullable = true)\n",
      " |-- totmultaajust: string (nullable = true)\n",
      " |-- totrecfinven: string (nullable = true)\n",
      " |-- totrecfinvenajust: string (nullable = true)\n",
      " |-- unitariofator: string (nullable = true)\n",
      " |-- modoarredondaitem: string (nullable = true)\n",
      " |-- estabeleciped: string (nullable = true)\n",
      " |-- emissaoped: string (nullable = true)\n",
      " |-- emissaopedh: string (nullable = true)\n",
      " |-- disponivelped: string (nullable = true)\n",
      " |-- usuarioped: string (nullable = true)\n",
      " |-- movimentach: string (nullable = true)\n",
      " |-- motivobloqueio: string (nullable = true)\n",
      " |-- pisrefobc: string (nullable = true)\n",
      " |-- svincdesconto: string (nullable = true)\n",
      " |-- crpessoacontrato: string (nullable = true)\n",
      " |-- scompetenciamensalidadebc: string (nullable = true)\n",
      " |-- smensalidadebc: string (nullable = true)\n",
      " |-- unitariocalc: string (nullable = true)\n",
      " |-- volqdetransp: string (nullable = true)\n",
      " |-- pisbc: string (nullable = true)\n",
      " |-- cofinsrefoaliq: string (nullable = true)\n",
      " |-- pisrefoaliq: string (nullable = true)\n",
      " |-- cofinsaliq: string (nullable = true)\n",
      " |-- cofinsbc: string (nullable = true)\n",
      " |-- isscodtrib: string (nullable = true)\n",
      " |-- irdeducaodep: string (nullable = true)\n",
      " |-- irdependentes: string (nullable = true)\n",
      " |-- caixa: string (nullable = true)\n",
      " |-- caixaped: string (nullable = true)\n",
      " |-- chorigembaixa: string (nullable = true)\n",
      " |-- numeroserie: string (nullable = true)\n",
      " |-- totservico: string (nullable = true)\n",
      " |-- serviconaopago: string (nullable = true)\n",
      " |-- conferencia: string (nullable = true)\n",
      " |-- conferidor: string (nullable = true)\n",
      " |-- sjurosfinparc: string (nullable = true)\n",
      " |-- chacessonfe: string (nullable = true)\n",
      " |-- contingencianfe: string (nullable = true)\n",
      " |-- emissaoh: string (nullable = true)\n",
      " |-- formularioserie: string (nullable = true)\n",
      " |-- pafs: string (nullable = true)\n",
      " |-- protocolonfe: string (nullable = true)\n",
      " |-- qtdformulario: string (nullable = true)\n",
      " |-- svinculamensalidadebc: string (nullable = true)\n",
      " |-- custocontant: string (nullable = true)\n",
      " |-- expedicao: string (nullable = true)\n",
      " |-- fatoradicionalopdestino: string (nullable = true)\n",
      " |-- fatoradicionalst: string (nullable = true)\n",
      " |-- fatorant: string (nullable = true)\n",
      " |-- fatormargemopdestino: string (nullable = true)\n",
      " |-- fatormargemst: string (nullable = true)\n",
      " |-- fatorreducaoopdestino: string (nullable = true)\n",
      " |-- fatorreducaost: string (nullable = true)\n",
      " |-- fatorreferenciaopdestino: string (nullable = true)\n",
      " |-- fatorreferenciast: string (nullable = true)\n",
      " |-- icmsstalopdestino: string (nullable = true)\n",
      " |-- itemant: string (nullable = true)\n",
      " |-- moedavalorant: string (nullable = true)\n",
      " |-- recebimento: string (nullable = true)\n",
      " |-- receptor: string (nullable = true)\n",
      " |-- tarefa: string (nullable = true)\n",
      " |-- unitarioant: string (nullable = true)\n",
      " |-- validadeh: string (nullable = true)\n",
      " |-- ccustresprojeto: string (nullable = true)\n",
      " |-- xdescperctotal: string (nullable = true)\n",
      " |-- tolermenosdiverg: string (nullable = true)\n",
      " |-- unimov: string (nullable = true)\n",
      " |-- acrescnegfin: string (nullable = true)\n",
      " |-- icmsstrepde: string (nullable = true)\n",
      " |-- chcorrecao: string (nullable = true)\n",
      " |-- prazogarantiam: string (nullable = true)\n",
      " |-- chcomplemento: string (nullable = true)\n",
      " |-- crpedidoorigem: string (nullable = true)\n",
      " |-- icmsstcredpres: string (nullable = true)\n",
      " |-- obsnota: string (nullable = true)\n",
      " |-- acresitem: string (nullable = true)\n",
      " |-- modalbcicms: string (nullable = true)\n",
      " |-- modalbcicmsst: string (nullable = true)\n",
      " |-- agregaicmsstperc: string (nullable = true)\n",
      " |-- markup: string (nullable = true)\n",
      " |-- redubcicmsstperc: string (nullable = true)\n",
      " |-- markupcalc: string (nullable = true)\n",
      " |-- redubcicmsperc: string (nullable = true)\n",
      " |-- crbaixacomplementada: string (nullable = true)\n",
      " |-- markuptabela: string (nullable = true)\n",
      " |-- pissittrib: string (nullable = true)\n",
      " |-- cofinssittrib: string (nullable = true)\n",
      " |-- obsdocumento: string (nullable = true)\n",
      " |-- precificabc: string (nullable = true)\n",
      " |-- prmaxconsumidor: string (nullable = true)\n",
      " |-- ipisittrib: string (nullable = true)\n",
      " |-- aprovacaocontrato: string (nullable = true)\n",
      " |-- assinaturapaf: string (nullable = true)\n",
      " |-- ativacaolinha: string (nullable = true)\n",
      " |-- contingencia: string (nullable = true)\n",
      " |-- detalhe: string (nullable = true)\n",
      " |-- docauxiliarvenda: string (nullable = true)\n",
      " |-- embarque: string (nullable = true)\n",
      " |-- fechamentocontrato: string (nullable = true)\n",
      " |-- icmsstaloporigem: string (nullable = true)\n",
      " |-- numeroserieecf: string (nullable = true)\n",
      " |-- numlinha: string (nullable = true)\n",
      " |-- ordimpressaodav: string (nullable = true)\n",
      " |-- pessoarepasse: string (nullable = true)\n",
      " |-- repasse: string (nullable = true)\n",
      " |-- statuslinha: string (nullable = true)\n",
      " |-- totalizadoresfiscais: string (nullable = true)\n",
      " |-- unimovorigem: string (nullable = true)\n",
      " |-- chpedbaixacancelamen: string (nullable = true)\n",
      " |-- pacote: string (nullable = true)\n",
      " |-- locescritufisdevol: string (nullable = true)\n",
      " |-- estabelecimento: string (nullable = true)\n",
      " |-- beneficiario: string (nullable = true)\n",
      " |-- tipocontingencianfe: string (nullable = true)\n",
      " |-- envionfe: string (nullable = true)\n",
      " |-- envionfeh: string (nullable = true)\n",
      " |-- rentabilidademinimausuario: string (nullable = true)\n",
      " |-- basecalculorentabilidade: string (nullable = true)\n",
      " |-- baidevolvida: string (nullable = true)\n",
      " |-- itemliquido: string (nullable = true)\n",
      " |-- declaracao: string (nullable = true)\n",
      " |-- declaracaoemissao: string (nullable = true)\n",
      " |-- tipodeclaracao: string (nullable = true)\n",
      " |-- registro: string (nullable = true)\n",
      " |-- averbacao: string (nullable = true)\n",
      " |-- taxacapatazia: string (nullable = true)\n",
      " |-- taxasiscomex: string (nullable = true)\n",
      " |-- multa: string (nullable = true)\n",
      " |-- taxadespachante: string (nullable = true)\n",
      " |-- fretemoeda: string (nullable = true)\n",
      " |-- indicadornaturezafrete: string (nullable = true)\n",
      " |-- datalancamentoextemporaneo: string (nullable = true)\n",
      " |-- reserva: string (nullable = true)\n",
      " |-- reservah: string (nullable = true)\n",
      " |-- vendaideal: string (nullable = true)\n",
      " |-- eficiencia: string (nullable = true)\n",
      " |-- certificado: string (nullable = true)\n",
      " |-- operacaocancelada: string (nullable = true)\n",
      " |-- cancelamensaldo: string (nullable = true)\n",
      " |-- canceladorsaldo: string (nullable = true)\n",
      " |-- rentabilidadepedido: string (nullable = true)\n",
      " |-- descsuframaicms: string (nullable = true)\n",
      " |-- oportganhocap: string (nullable = true)\n",
      " |-- descsuframapis: string (nullable = true)\n",
      " |-- descsuframacofins: string (nullable = true)\n",
      " |-- rentabilidadeitem: string (nullable = true)\n",
      " |-- cfocancelamen: string (nullable = true)\n",
      " |-- natoperacao: string (nullable = true)\n",
      " |-- icmsantecbc: string (nullable = true)\n",
      " |-- icmspautaantecipado: string (nullable = true)\n",
      " |-- icmsdifalbc: string (nullable = true)\n",
      " |-- pispauta: string (nullable = true)\n",
      " |-- cofinspauta: string (nullable = true)\n",
      " |-- localexecucaoservico: string (nullable = true)\n",
      " |-- adicao: string (nullable = true)\n",
      " |-- sequencialadicao: string (nullable = true)\n",
      " |-- tiposaida: string (nullable = true)\n",
      " |-- datadesembaraco: string (nullable = true)\n",
      " |-- localembarquedesembarque: string (nullable = true)\n",
      " |-- prevenda: string (nullable = true)\n",
      " |-- listaprod: string (nullable = true)\n",
      " |-- quantidadeagrupa: string (nullable = true)\n",
      " |-- licenca: string (nullable = true)\n",
      " |-- origem: string (nullable = true)\n",
      " |-- saidaorigem: string (nullable = true)\n",
      " |-- destino: string (nullable = true)\n",
      " |-- chegadadestino: string (nullable = true)\n",
      " |-- unitariomoedanac: string (nullable = true)\n",
      " |-- itemmoeda: string (nullable = true)\n",
      " |-- tipodevolucao: string (nullable = true)\n",
      " |-- subtotal: string (nullable = true)\n",
      " |-- totalmoeda: string (nullable = true)\n",
      " |-- disponivelnegociacao: string (nullable = true)\n",
      " |-- eventobloqueiobaixa: string (nullable = true)\n",
      " |-- statusnfe: string (nullable = true)\n",
      " |-- tipoemissaonfe: string (nullable = true)\n",
      " |-- unitariofatoragrupa: string (nullable = true)\n",
      " |-- obsfixa: string (nullable = true)\n",
      " |-- chimportacao: string (nullable = true)\n",
      " |-- nomearquivoimport: string (nullable = true)\n",
      " |-- origemunitario: string (nullable = true)\n",
      " |-- negociadoitem: string (nullable = true)\n",
      " |-- codacesso: string (nullable = true)\n",
      " |-- totalnegociado: string (nullable = true)\n",
      " |-- adiantado: string (nullable = true)\n",
      " |-- chunificadora: string (nullable = true)\n",
      " |-- senha: string (nullable = true)\n",
      " |-- vencfatura: string (nullable = true)\n",
      " |-- atraso: string (nullable = true)\n",
      " |-- carcobranca: string (nullable = true)\n",
      " |-- carrecfinatr: string (nullable = true)\n",
      " |-- carrecfinfin: string (nullable = true)\n",
      " |-- chacessonfeorigem: string (nullable = true)\n",
      " |-- totalcomercial: string (nullable = true)\n",
      " |-- eventobloqueiodevolucao: string (nullable = true)\n",
      " |-- cro: string (nullable = true)\n",
      " |-- crz: string (nullable = true)\n",
      " |-- totcobranca: string (nullable = true)\n",
      " |-- totcobrancaajust: string (nullable = true)\n",
      " |-- tac: string (nullable = true)\n",
      " |-- seventoarquivo: string (nullable = true)\n",
      " |-- spedidoorigem: string (nullable = true)\n",
      " |-- scontrato: string (nullable = true)\n",
      " |-- sprodutosaude: string (nullable = true)\n",
      " |-- programacamontagem: string (nullable = true)\n",
      " |-- programacamontagemh: string (nullable = true)\n",
      " |-- tipomontagem: string (nullable = true)\n",
      " |-- locescritutransf: string (nullable = true)\n",
      " |-- chpedlocesctransf: string (nullable = true)\n",
      " |-- pedlocesctransf: string (nullable = true)\n",
      " |-- chpedlocesctransforigem: string (nullable = true)\n",
      " |-- pedlocesctransforigem: string (nullable = true)\n",
      " |-- icmsbccrede: string (nullable = true)\n",
      " |-- icmsaliqcrede: string (nullable = true)\n",
      " |-- volume: string (nullable = true)\n",
      " |-- sobservacaofaturamento: string (nullable = true)\n",
      " |-- motorista: string (nullable = true)\n",
      " |-- placa: string (nullable = true)\n",
      " |-- motivocancelamen: string (nullable = true)\n",
      " |-- obscancelamen: string (nullable = true)\n",
      " |-- dataembarque: string (nullable = true)\n",
      " |-- dataembarqueh: string (nullable = true)\n",
      " |-- spensao: string (nullable = true)\n",
      " |-- ordemcarga: string (nullable = true)\n",
      " |-- descitemkit: string (nullable = true)\n",
      " |-- acresitemkit: string (nullable = true)\n",
      " |-- afrmm: string (nullable = true)\n",
      " |-- assinaturapafitem: string (nullable = true)\n",
      " |-- drawback: string (nullable = true)\n",
      " |-- indpres: string (nullable = true)\n",
      " |-- tipoviatransp: string (nullable = true)\n",
      " |-- emissaoutc: string (nullable = true)\n",
      " |-- emissaohutc: string (nullable = true)\n",
      " |-- dataagendamento: string (nullable = true)\n",
      " |-- dataagendamentoh: string (nullable = true)\n",
      " |-- icmsdeson: string (nullable = true)\n",
      " |-- descicms: string (nullable = true)\n",
      " |-- icmspercdif: string (nullable = true)\n",
      " |-- icmsdif: string (nullable = true)\n",
      " |-- sorigem: string (nullable = true)\n",
      " |-- slotacao: string (nullable = true)\n",
      " |-- chacessocanc: string (nullable = true)\n",
      " |-- consumidoroperacao: string (nullable = true)\n",
      " |-- datacancsistemaemissor: string (nullable = true)\n",
      " |-- datasistemaemissor: string (nullable = true)\n",
      " |-- emissaodoc: string (nullable = true)\n",
      " |-- emissaodoch: string (nullable = true)\n",
      " |-- horacancsistemaemissor: string (nullable = true)\n",
      " |-- horasistemaemissor: string (nullable = true)\n",
      " |-- numcomputador: string (nullable = true)\n",
      " |-- numerocanc: string (nullable = true)\n",
      " |-- ultnumsessaosat: string (nullable = true)\n",
      " |-- emissaoorigem: string (nullable = true)\n",
      " |-- aplicativoemissor: string (nullable = true)\n",
      " |-- dataselotransito: string (nullable = true)\n",
      " |-- protocoloselotransito: string (nullable = true)\n",
      " |-- premovimentac: string (nullable = true)\n",
      " |-- premovimentach: string (nullable = true)\n",
      " |-- previsaoemissaodoc: string (nullable = true)\n",
      " |-- outdespacessorias: string (nullable = true)\n",
      " |-- totaldespacessorias: string (nullable = true)\n",
      " |-- icmsaliqufpessoa: string (nullable = true)\n",
      " |-- icmsbcufpessoa: string (nullable = true)\n",
      " |-- icmsufpessoa: string (nullable = true)\n",
      " |-- icmsdifpessoalocescritu: string (nullable = true)\n",
      " |-- icmspartufpessoa: string (nullable = true)\n",
      " |-- icmspartuflocescritu: string (nullable = true)\n",
      " |-- bcfcp: string (nullable = true)\n",
      " |-- aliquotafcp: string (nullable = true)\n",
      " |-- fundocombprob: string (nullable = true)\n",
      " |-- icmsstdevol: string (nullable = true)\n",
      " |-- icmsstbcdevol: string (nullable = true)\n",
      " |-- configresiduo: string (nullable = true)\n",
      " |-- configrateio: string (nullable = true)\n",
      " |-- nsutef: string (nullable = true)\n",
      " |-- tribfederal: string (nullable = true)\n",
      " |-- tribestadual: string (nullable = true)\n",
      " |-- tribmunicipal: string (nullable = true)\n",
      " |-- regratribincid: string (nullable = true)\n",
      " |-- snumero: string (nullable = true)\n",
      " |-- semissaonota: string (nullable = true)\n",
      " |-- sprestador: string (nullable = true)\n",
      " |-- assinaturamd5pafecf: string (nullable = true)\n",
      " |-- regimeesptrib: string (nullable = true)\n",
      " |-- regimereco: string (nullable = true)\n",
      " |-- regimerecoorigem: string (nullable = true)\n",
      " |-- totalbruto: string (nullable = true)\n",
      " |-- totalliquido: string (nullable = true)\n",
      " |-- ordemrl: string (nullable = true)\n",
      " |-- dataregistro: string (nullable = true)\n",
      " |-- mensagem: string (nullable = true)\n",
      " |-- ipidevol: string (nullable = true)\n",
      " |-- ipibcdevol: string (nullable = true)\n",
      " |-- icmspropriobc: string (nullable = true)\n",
      " |-- icmsproprioaliq: string (nullable = true)\n",
      " |-- icmsproprio: string (nullable = true)\n",
      " |-- icmsdifalcrede: string (nullable = true)\n",
      " |-- pisaliqcrede: string (nullable = true)\n",
      " |-- pisbccrede: string (nullable = true)\n",
      " |-- piscrede: string (nullable = true)\n",
      " |-- cofinsaliqcrede: string (nullable = true)\n",
      " |-- cofinsbccrede: string (nullable = true)\n",
      " |-- cofinscrede: string (nullable = true)\n",
      " |-- tipoembarque: string (nullable = true)\n",
      " |-- numeroembarque: string (nullable = true)\n",
      " |-- paispessoaop: string (nullable = true)\n",
      " |-- ceppessoaop: string (nullable = true)\n",
      " |-- ufpessoaop: string (nullable = true)\n",
      " |-- localidadepessoaop: string (nullable = true)\n",
      " |-- zonacidadepessoaop: string (nullable = true)\n",
      " |-- sublocalidadepessoaop: string (nullable = true)\n",
      " |-- tipologradouropessoaop: string (nullable = true)\n",
      " |-- logradouropessoaop: string (nullable = true)\n",
      " |-- numeropessoaop: string (nullable = true)\n",
      " |-- complementopessoaop: string (nullable = true)\n",
      " |-- pontoreferpessoaop: string (nullable = true)\n",
      " |-- paislocescrituop: string (nullable = true)\n",
      " |-- ceplocescrituop: string (nullable = true)\n",
      " |-- uflocescrituop: string (nullable = true)\n",
      " |-- localidadelocescrituop: string (nullable = true)\n",
      " |-- zonacidadelocescrituop: string (nullable = true)\n",
      " |-- sublocalidadelocescrituop: string (nullable = true)\n",
      " |-- tipologradlocescrituop: string (nullable = true)\n",
      " |-- logradourolocescrituop: string (nullable = true)\n",
      " |-- numerolocescrituop: string (nullable = true)\n",
      " |-- complementolocescrituop: string (nullable = true)\n",
      " |-- pontoreferlocescrituop: string (nullable = true)\n",
      " |-- icmscodbenef: string (nullable = true)\n",
      " |-- bcfcpst: string (nullable = true)\n",
      " |-- aliquotafcpst: string (nullable = true)\n",
      " |-- fcp: string (nullable = true)\n",
      " |-- fcpcrede: string (nullable = true)\n",
      " |-- fcpst: string (nullable = true)\n",
      " |-- fcpstcrede: string (nullable = true)\n",
      " |-- inssretsub: string (nullable = true)\n",
      " |-- inssseg15: string (nullable = true)\n",
      " |-- inssseg20: string (nullable = true)\n",
      " |-- inssseg25: string (nullable = true)\n",
      " |-- gilratbc: string (nullable = true)\n",
      " |-- gilrataliq: string (nullable = true)\n",
      " |-- gilrat: string (nullable = true)\n",
      " |-- senarbc: string (nullable = true)\n",
      " |-- senaraliq: string (nullable = true)\n",
      " |-- senar: string (nullable = true)\n",
      " |-- zinfofiscal: string (nullable = true)\n",
      " |-- zunidmedidafornecedor: string (nullable = true)\n",
      " |-- zsestsenatbc: string (nullable = true)\n",
      " |-- zsestsenataliq: string (nullable = true)\n",
      " |-- zsestsenat: string (nullable = true)\n",
      " |-- zsestsenatretido: string (nullable = true)\n",
      " |-- obsvendentfut: string (nullable = true)\n",
      " |-- formacalculoir: string (nullable = true)\n",
      " |-- flagativo: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tabela 'local.bronze.stgPedidos' criada/populada com sucesso!\n",
      "\n",
      "üöÄ Todas as tabelas foram processadas com sucesso.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from dotenv import load_dotenv\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Carrega vari√°veis de ambiente do .env\n",
    "load_dotenv()\n",
    "s3_endpoint = os.getenv(\"S3_ENDPOINT\")\n",
    "s3_access_key = os.getenv(\"S3_ACCESS_KEY\")\n",
    "s3_secret_key = os.getenv(\"S3_SECRET_KEY\")\n",
    "\n",
    "print(f\"üîê Endpoint: {s3_endpoint} | Access Key: {s3_access_key}\")\n",
    "\n",
    "# Conex√£o com MinIO via boto3\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=s3_endpoint,\n",
    "    aws_access_key_id=s3_access_key,\n",
    "    aws_secret_access_key=s3_secret_key,\n",
    "    config=Config(signature_version=\"s3v4\"),\n",
    "    region_name=\"us-east-1\"\n",
    ")\n",
    "\n",
    "# Lista arquivos no bucket \"ingestion\"\n",
    "bucket_name = \"ingestion\"\n",
    "response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "csv_files = [obj[\"Key\"] for obj in response.get(\"Contents\", []) if obj[\"Key\"].endswith(\".csv\")]\n",
    "\n",
    "# Agrupa arquivos por prefixo\n",
    "prefix_groups = defaultdict(list)\n",
    "for file in csv_files:\n",
    "    match = re.match(r\"(.+?)_\\d+\\.csv\", file)\n",
    "    prefix = match.group(1) if match else file.replace(\".csv\", \"\")\n",
    "    prefix_groups[prefix].append(file)\n",
    "\n",
    "# Cria sess√£o Spark com suporte a Iceberg + MinIO (S3A)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"IcebergMinIOIngestion\") \\\n",
    "    .config(\"spark.jars\", \"/opt/spark/jars/iceberg-spark-runtime-3.5_2.12-1.6.0.jar\") \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "    .config(\"spark.sql.catalog.local\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.local.type\", \"hadoop\") \\\n",
    "    .config(\"spark.sql.catalog.local.warehouse\", \"s3a://datalake/iceberg\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", s3_endpoint) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", s3_access_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", s3_secret_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.AbstractFileSystem.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3A\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# Processa os arquivos agrupados por prefixo\n",
    "for prefix, files in prefix_groups.items():\n",
    "    print(f\"\\nüîß Processando prefixo: {prefix}\")\n",
    "\n",
    "    file_paths = [f\"s3a://{bucket_name}/{file}\" for file in files]\n",
    "    df = spark.read.option(\"header\", \"true\").csv(file_paths)\n",
    "\n",
    "    # Exibe o schema inferido\n",
    "    df.printSchema()\n",
    "\n",
    "    # Prepara os campos para cria√ß√£o da tabela Iceberg\n",
    "    cols = \", \".join([f\"{field.name} STRING\" for field in df.schema.fields])\n",
    "\n",
    "    # Cria tabela Iceberg se n√£o existir\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS local.bronze.{prefix} (\n",
    "            {cols}\n",
    "        )\n",
    "        USING iceberg\n",
    "    \"\"\")\n",
    "\n",
    "    # Inser√ß√£o com append\n",
    "    df.writeTo(f\"local.bronze.{prefix}\").append()\n",
    "    print(f\"‚úÖ Tabela 'local.bronze.{prefix}' criada/populada com sucesso!\")\n",
    "\n",
    "print(\"\\nüöÄ Todas as tabelas foram processadas com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d57cbba-574f-419a-b17f-1159de35a70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"level\": \"INFO\", \"message\": \"üîê Endpoint: http://minio:9000 | Access Key: mini***\"}\n",
      "{\"level\": \"INFO\", \"message\": \"1 arquivos .csv encontrados no bucket.\"}\n",
      "25/04/20 01:10:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/20 01:10:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "{\"level\": \"INFO\", \"message\": \"üîß Processando prefixo: clientes\"}\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- nome: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- data_cadastro: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- created_at: timestamp (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"level\": \"INFO\", \"message\": \"‚úÖ Tabela 'local.bronze.clientes' criada/populada com sucesso!\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üöÄ Todas as tabelas foram processadas e os arquivos .csv foram exclu√≠dos com sucesso.\"}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from dotenv import load_dotenv\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import current_timestamp\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# -------------------------\n",
    "# Configura√ß√£o do Logging\n",
    "# -------------------------\n",
    "def setup_logger():\n",
    "    logger = logging.getLogger(\"minio_upload\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    handler = logging.StreamHandler()\n",
    "    formatter = logging.Formatter(\n",
    "        fmt='{\"level\": \"%(levelname)s\", \"message\": \"%(message)s\"}'\n",
    "    )\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "logger = setup_logger()\n",
    "\n",
    "# Carrega vari√°veis de ambiente do .env\n",
    "load_dotenv()\n",
    "s3_endpoint = os.getenv(\"S3_ENDPOINT\")\n",
    "s3_access_key = os.getenv(\"S3_ACCESS_KEY\")\n",
    "s3_secret_key = os.getenv(\"S3_SECRET_KEY\")\n",
    "\n",
    "logger.info(f\"üîê Endpoint: {s3_endpoint} | Access Key: {s3_access_key[:4]}***\")\n",
    "\n",
    "# Conex√£o com MinIO via boto3\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=s3_endpoint,\n",
    "    aws_access_key_id=s3_access_key,\n",
    "    aws_secret_access_key=s3_secret_key,\n",
    "    config=Config(signature_version=\"s3v4\"),\n",
    "    region_name=\"us-east-1\"\n",
    ")\n",
    "\n",
    "# Lista arquivos no bucket \"ingestion\"\n",
    "bucket_name = \"ingestion\"\n",
    "response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "csv_files = [obj[\"Key\"] for obj in response.get(\"Contents\", []) if obj[\"Key\"].endswith(\".csv\")]\n",
    "\n",
    "# Valida√ß√£o: existem arquivos CSV?\n",
    "if not csv_files:\n",
    "    logger.info(\"Nenhum arquivo .csv encontrado no bucket 'ingestion'. Abortando script.\", level=\"WARNING\")\n",
    "    exit(0)\n",
    "\n",
    "\n",
    "logger.info(f\"{len(csv_files)} arquivos .csv encontrados no bucket.\")\n",
    "\n",
    "# Agrupa arquivos por prefixo\n",
    "prefix_groups = defaultdict(list)\n",
    "for file in csv_files:\n",
    "    match = re.match(r\"(.+?)_\\d+\\.csv\", file)\n",
    "    prefix = match.group(1) if match else file.replace(\".csv\", \"\")\n",
    "    prefix_groups[prefix].append(file)\n",
    "\n",
    "# Cria sess√£o Spark com suporte a Iceberg + MinIO (S3A)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"IcebergMinIOIngestion\") \\\n",
    "    .config(\"spark.jars\", \"/opt/spark/jars/iceberg-spark-runtime-3.5_2.12-1.6.0.jar\") \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "    .config(\"spark.sql.catalog.local\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.local.type\", \"hadoop\") \\\n",
    "    .config(\"spark.sql.catalog.local.warehouse\", \"s3a://datalake/iceberg\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", s3_endpoint) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", s3_access_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", s3_secret_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.AbstractFileSystem.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3A\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# Processa os arquivos agrupados por prefixo\n",
    "for prefix, files in prefix_groups.items():\n",
    "    logger.info(f\"üîß Processando prefixo: {prefix}\")\n",
    "\n",
    "    file_paths = [f\"s3a://{bucket_name}/{file}\" for file in files]\n",
    "    df = spark.read.option(\"header\", \"true\").csv(file_paths)\n",
    "\n",
    "    # Adiciona a coluna created_at com a data/hora atual\n",
    "    from pyspark.sql.functions import current_timestamp\n",
    "    df = df.withColumn(\"created_at\", current_timestamp())\n",
    "\n",
    "    # Exibe o schema inferido\n",
    "    df.printSchema()\n",
    "\n",
    "    # Prepara os campos para cria√ß√£o da tabela Iceberg\n",
    "    cols = \", \".join([f\"{field.name} STRING\" for field in df.schema.fields])\n",
    "\n",
    "    # Cria tabela Iceberg se n√£o existir\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS local.bronze.{prefix} (\n",
    "            {cols}\n",
    "        )\n",
    "        USING iceberg\n",
    "    \"\"\")\n",
    "\n",
    "    # Inser√ß√£o com append\n",
    "    #df.writeTo(f\"local.bronze.{prefix}\").append()\n",
    "    #Mais performatico para grandes volumes\n",
    "    df.writeTo(f\"local.bronze.{prefix}\").overwritePartitions()\n",
    "    logger.info(f\"‚úÖ Tabela 'local.bronze.{prefix}' criada/populada com sucesso!\")\n",
    "\n",
    "    # Remove arquivos processados do bucket\n",
    "    for file in files:\n",
    "        s3.delete_object(Bucket=bucket_name, Key=file)\n",
    "        logger.info(f\"üóëÔ∏è Arquivo deletado do bucket: {file}\")\n",
    "\n",
    "logger.info(\"üöÄ Todas as tabelas foram processadas e os arquivos .csv foram exclu√≠dos com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10039b1e-a32b-4e04-97e8-59bc09c964ac",
   "metadata": {},
   "source": [
    "# TESTE COM API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e47a606e-27bd-4bdd-b2ac-8c5470d86519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"level\": \"INFO\", \"message\": \"üîê Endpoint: http://minio:9000 | Access Key: mini***\"}\n",
      "{\"level\": \"INFO\", \"message\": \"20 arquivos .csv encontrados no bucket.\"}\n",
      "25/04/20 15:06:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "{\"level\": \"INFO\", \"message\": \"üîß Processando prefixo: clientes\"}\n",
      "{\"level\": \"INFO\", \"message\": \"‚úÖ Inseridos novos registros na tabela 'local.bronze.clientes'.\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üßπ Compacta√ß√£o de arquivos executada na tabela 'local.bronze.clientes'.\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_01.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_02.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_03.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_04.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_05.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_06.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_07.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_08.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_09.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_10.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_11.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_12.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_13.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_14.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_15.csv\"}\n",
      "25/04/20 15:14:56 ERROR Executor: Exception in task 2.0 in stage 10.0 (TID 20)\n",
      "org.apache.spark.SparkFileNotFoundException: No such file or directory: s3a://ingestion/clientes_09.csv\n",
      "It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.readCurrentFileNotFoundError(QueryExecutionErrors.scala:780)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:220)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:279)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.hashAgg_doAggregateWithKeys_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n",
      "25/04/20 15:14:56 ERROR TaskSetManager: Task 2 in stage 10.0 failed 1 times; aborting job\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_16.csv\"}]\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_17.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_18.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_19.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_20.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üöÄ Todas as tabelas foram processadas e os arquivos .csv foram exclu√≠dos com sucesso.\"}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from dotenv import load_dotenv\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import current_timestamp\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# -------------------------\n",
    "# Configura√ß√£o do Logging\n",
    "# -------------------------\n",
    "def setup_logger():\n",
    "    # Evita m√∫ltiplos handlers\n",
    "    logger = logging.getLogger(\"minio_upload\")\n",
    "    if logger.handlers:  # Remove handlers existentes\n",
    "        logger.handlers = []\n",
    "    logger.setLevel(logging.INFO)\n",
    "    handler = logging.StreamHandler()\n",
    "    formatter = logging.Formatter(fmt='{\"level\": \"%(levelname)s\", \"message\": \"%(message)s\"}')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    return logger\n",
    "\n",
    "logger = setup_logger()\n",
    "\n",
    "# Carrega vari√°veis de ambiente do .env\n",
    "load_dotenv()\n",
    "s3_endpoint = os.getenv(\"S3_ENDPOINT\")\n",
    "s3_access_key = os.getenv(\"S3_ACCESS_KEY\")\n",
    "s3_secret_key = os.getenv(\"S3_SECRET_KEY\")\n",
    "\n",
    "logger.info(f\"üîê Endpoint: {s3_endpoint} | Access Key: {s3_access_key[:4]}***\")\n",
    "\n",
    "# Conex√£o com MinIO via boto3\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=s3_endpoint,\n",
    "    aws_access_key_id=s3_access_key,\n",
    "    aws_secret_access_key=s3_secret_key,\n",
    "    config=Config(signature_version=\"s3v4\"),\n",
    "    region_name=\"us-east-1\"\n",
    ")\n",
    "\n",
    "# Lista arquivos no bucket \"ingestion\"\n",
    "bucket_name = \"ingestion\"\n",
    "response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "csv_files = [obj[\"Key\"] for obj in response.get(\"Contents\", []) if obj[\"Key\"].endswith(\".csv\")]\n",
    "\n",
    "# Valida√ß√£o: existem arquivos CSV?\n",
    "if not csv_files:\n",
    "    logger.info(\"Nenhum arquivo .csv encontrado no bucket 'ingestion'. Abortando script.\")\n",
    "    exit(0)\n",
    "\n",
    "logger.info(f\"{len(csv_files)} arquivos .csv encontrados no bucket.\")\n",
    "\n",
    "# Agrupa arquivos por prefixo\n",
    "prefix_groups = defaultdict(list)\n",
    "for file in csv_files:\n",
    "    match = re.match(r\"(.+?)_\\d+\\.csv\", file)\n",
    "    prefix = match.group(1) if match else file.replace(\".csv\", \"\")\n",
    "    prefix_groups[prefix].append(file)\n",
    "\n",
    "# Cria sess√£o Spark com suporte a Iceberg + MinIO (S3A)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"IcebergMinIOIngestion\") \\\n",
    "    .config(\"spark.jars\", \"/opt/spark/jars/iceberg-spark-runtime-3.5_2.12-1.6.0.jar\") \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "    .config(\"spark.sql.catalog.local\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.local.type\", \"hadoop\") \\\n",
    "    .config(\"spark.sql.catalog.local.warehouse\", \"s3a://datalake/iceberg\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", s3_endpoint) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", s3_access_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", s3_secret_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.fast.upload\", \"true\") \\\n",
    "    .config(\"spark.sql.catalog.local.default-namespace\", \"default\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# Processa os arquivos agrupados por prefixo\n",
    "for prefix, files in prefix_groups.items():\n",
    "    logger.info(f\"üîß Processando prefixo: {prefix}\")\n",
    "\n",
    "    # --------------------------------\n",
    "    # Camada Bronze\n",
    "    # --------------------------------\n",
    "    file_paths = [f\"s3a://{bucket_name}/{file}\" for file in files]\n",
    "    df = spark.read.option(\"header\", \"true\").csv(file_paths)\n",
    "\n",
    "    # Adiciona a coluna created_at com a data/hora atual\n",
    "    df = df.withColumn(\"created_at\", current_timestamp())\n",
    "\n",
    "    # Valida√ß√£o: Remove duplicatas e nulos na chave prim√°ria (id)\n",
    "    df = df.dropDuplicates([\"id\"]).filter(\"id IS NOT NULL\")\n",
    "\n",
    "    # Exibe o schema inferido\n",
    "    #df.printSchema()\n",
    "\n",
    "    # Prepara os campos para cria√ß√£o da tabela Iceberg\n",
    "    cols = \", \".join([f\"{field.name} STRING\" for field in df.schema.fields if field.name != \"created_at\"] + [\"created_at TIMESTAMP\"])\n",
    "\n",
    "    # Cria tabela Iceberg na camada bronze se n√£o existir\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS local.bronze.{prefix} (\n",
    "            {cols}\n",
    "        )\n",
    "        USING iceberg\n",
    "        PARTITIONED BY (days(created_at))\n",
    "        TBLPROPERTIES (\n",
    "            'write.format.default'='parquet',\n",
    "            'write.parquet.compression-codec'='snappy',\n",
    "            'write.target-file-size-bytes'='134217728',\n",
    "            'commit.retry.num-retries'='10'\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    # Carrega a tabela bronze existente\n",
    "    bronze_df = spark.table(f\"local.bronze.{prefix}\")\n",
    "\n",
    "    # Separa registros para atualiza√ß√£o (existem na tabela bronze) e inser√ß√£o (novos)\n",
    "    existing_ids = bronze_df.select(\"id\").distinct()\n",
    "    update_df = df.join(existing_ids, \"id\", \"inner\")  # Registros que j√° existem\n",
    "    insert_df = df.join(existing_ids, \"id\", \"left_anti\")  # Registros novos\n",
    "\n",
    "    # Escreve novos registros (inser√ß√£o)\n",
    "    if not insert_df.isEmpty():\n",
    "        insert_df.writeTo(f\"local.bronze.{prefix}\").append()\n",
    "        logger.info(f\"‚úÖ Inseridos novos registros na tabela 'local.bronze.{prefix}'.\")\n",
    "\n",
    "    # Escreve atualiza√ß√µes (sobrescreve parti√ß√µes afetadas)\n",
    "    if not update_df.isEmpty():\n",
    "        update_df.writeTo(f\"local.bronze.{prefix}\").overwritePartitions()\n",
    "        logger.info(f\"‚úÖ Atualizados registros existentes na tabela 'local.bronze.{prefix}'.\")\n",
    "\n",
    "    # Manuten√ß√£o na camada bronze\n",
    "    spark.sql(f\"CALL local.system.rewrite_data_files(table => 'local.bronze.{prefix}')\")\n",
    "    logger.info(f\"üßπ Compacta√ß√£o de arquivos executada na tabela 'local.bronze.{prefix}'.\")\n",
    "\n",
    "    # Remove arquivos processados do bucket\n",
    "    for file in files:\n",
    "        s3.delete_object(Bucket=bucket_name, Key=file)\n",
    "        logger.info(f\"üóëÔ∏è Arquivo deletado do bucket: {file}\")\n",
    "\n",
    "logger.info(\"üöÄ Todas as tabelas foram processadas e os arquivos .csv foram exclu√≠dos com sucesso.\")\n",
    "\n",
    "# Fecha a sess√£o Spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "765eea7a-01fb-4b1d-afee-eacd385e78d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.1\n"
     ]
    }
   ],
   "source": [
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75eb1f3e-ea06-4399-a9c9-b34a8fa26c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"level\": \"INFO\", \"message\": \"üîê Endpoint: http://minio:9000 | Access Key: mini***\"}\n",
      "{\"level\": \"INFO\", \"message\": \"20 arquivos .csv encontrados no bucket.\"}\n",
      "25/04/21 09:57:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/21 09:57:34 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "{\"level\": \"INFO\", \"message\": \"üîß Processando prefixo: clientes\"}\n",
      "{\"level\": \"INFO\", \"message\": \"‚úÖ Atualizados registros existentes na tabela 'local.bronze.clientes'.\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üßπ Compacta√ß√£o de arquivos executada na tabela 'local.bronze.clientes'.\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_01.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_02.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_03.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_04.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_05.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_06.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_07.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_08.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_09.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_10.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_11.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_12.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_13.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_14.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_15.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_16.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_17.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_18.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_19.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üóëÔ∏è Arquivo deletado do bucket: clientes_20.csv\"}\n",
      "{\"level\": \"INFO\", \"message\": \"üöÄ Todas as tabelas foram processadas e os arquivos .csv foram exclu√≠dos com sucesso.\"}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "from dotenv import load_dotenv\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import current_timestamp\n",
    "import logging\n",
    "import os  # Adicionado para importar os.getenv\n",
    "\n",
    "# -------------------------\n",
    "# Configura√ß√£o do Logging\n",
    "# -------------------------\n",
    "def setup_logger():\n",
    "    logger = logging.getLogger(\"minio_upload\")\n",
    "    if logger.handlers:\n",
    "        logger.handlers = []\n",
    "    logger.setLevel(logging.INFO)\n",
    "    handler = logging.StreamHandler()\n",
    "    formatter = logging.Formatter(fmt='{\"level\": \"%(levelname)s\", \"message\": \"%(message)s\"}')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    return logger\n",
    "\n",
    "logger = setup_logger()\n",
    "\n",
    "# Carrega vari√°veis de ambiente do .env\n",
    "load_dotenv()\n",
    "s3_endpoint = os.getenv(\"S3_ENDPOINT\")\n",
    "s3_access_key = os.getenv(\"S3_ACCESS_KEY\")\n",
    "s3_secret_key = os.getenv(\"S3_SECRET_KEY\")\n",
    "\n",
    "logger.info(f\"üîê Endpoint: {s3_endpoint} | Access Key: {s3_access_key[:4]}***\")\n",
    "\n",
    "# Conex√£o com MinIO via boto3\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=s3_endpoint,\n",
    "    aws_access_key_id=s3_access_key,\n",
    "    aws_secret_access_key=s3_secret_key,\n",
    "    config=Config(signature_version=\"s3v4\"),\n",
    "    region_name=\"us-east-1\"\n",
    ")\n",
    "\n",
    "# Lista arquivos no bucket \"ingestion\"\n",
    "bucket_name = \"ingestion\"\n",
    "response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "csv_files = [obj[\"Key\"] for obj in response.get(\"Contents\", []) if obj[\"Key\"].endswith(\".csv\")]\n",
    "\n",
    "# Valida√ß√£o: existem arquivos CSV?\n",
    "if not csv_files:\n",
    "    logger.info(\"Nenhum arquivo .csv encontrado no bucket 'ingestion'. Abortando script.\")\n",
    "    exit(0)\n",
    "\n",
    "logger.info(f\"{len(csv_files)} arquivos .csv encontrados no bucket.\")\n",
    "\n",
    "# Agrupa arquivos por prefixo\n",
    "prefix_groups = defaultdict(list)\n",
    "for file in csv_files:\n",
    "    match = re.match(r\"(.+?)_\\d+\\.csv\", file)\n",
    "    prefix = match.group(1) if match else file.replace(\".csv\", \"\")\n",
    "    prefix_groups[prefix].append(file)\n",
    "\n",
    "# Cria sess√£o Spark com suporte a Iceberg + MinIO (S3A)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"IcebergMinIOIngestion\") \\\n",
    "    .config(\"spark.jars\", \"/opt/spark/jars/iceberg-spark-runtime-3.5_2.12-1.6.0.jar\") \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "    .config(\"spark.sql.catalog.local\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.local.type\", \"hadoop\") \\\n",
    "    .config(\"spark.sql.catalog.local.warehouse\", \"s3a://datalake/iceberg\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", s3_endpoint) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", s3_access_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", s3_secret_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.fast.upload\", \"true\") \\\n",
    "    .config(\"spark.sql.catalog.local.default-namespace\", \"default\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# Lista para armazenar arquivos a serem deletados\n",
    "files_to_delete = []\n",
    "\n",
    "# Processa os arquivos agrupados por prefixo\n",
    "for prefix, files in prefix_groups.items():\n",
    "    logger.info(f\"üîß Processando prefixo: {prefix}\")\n",
    "\n",
    "    # --------------------------------\n",
    "    # Camada Bronze\n",
    "    # --------------------------------\n",
    "    file_paths = [f\"s3a://{bucket_name}/{file}\" for file in files]\n",
    "    df = spark.read.option(\"header\", \"true\").csv(file_paths)\n",
    "\n",
    "    # Adiciona a coluna created_at com a data/hora atual\n",
    "    df = df.withColumn(\"created_at\", current_timestamp())\n",
    "\n",
    "    # Valida√ß√£o: Remove duplicatas e nulos na chave prim√°ria (id)\n",
    "    df = df.dropDuplicates([\"id\"]).filter(\"id IS NOT NULL\")\n",
    "\n",
    "    # Prepara os campos para cria√ß√£o da tabela Iceberg\n",
    "    cols = \", \".join([f\"{field.name} STRING\" for field in df.schema.fields if field.name != \"created_at\"] + [\"created_at TIMESTAMP\"])\n",
    "\n",
    "    # Cria tabela Iceberg na camada bronze se n√£o existir\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS local.bronze.{prefix} (\n",
    "            {cols}\n",
    "        )\n",
    "        USING iceberg\n",
    "        PARTITIONED BY (days(created_at))\n",
    "        TBLPROPERTIES (\n",
    "            'write.format.default'='parquet',\n",
    "            'write.parquet.compression-codec'='snappy',\n",
    "            'write.target-file-size-bytes'='134217728',\n",
    "            'commit.retry.num-retries'='10'\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    # Carrega a tabela bronze existente\n",
    "    bronze_df = spark.table(f\"local.bronze.{prefix}\")\n",
    "\n",
    "    # Separa registros para atualiza√ß√£o (existem na tabela bronze) e inser√ß√£o (novos)\n",
    "    existing_ids = bronze_df.select(\"id\").distinct()\n",
    "    update_df = df.join(existing_ids, \"id\", \"inner\")  # Registros que j√° existem\n",
    "    insert_df = df.join(existing_ids, \"id\", \"left_anti\")  # Registros novos\n",
    "\n",
    "    # Escreve novos registros (inser√ß√£o)\n",
    "    if not insert_df.isEmpty():\n",
    "        insert_df.writeTo(f\"local.bronze.{prefix}\").append()\n",
    "        logger.info(f\"‚úÖ Inseridos novos registros na tabela 'local.bronze.{prefix}'.\")\n",
    "\n",
    "    # Escreve atualiza√ß√µes (sobrescreve parti√ß√µes afetadas)\n",
    "    if not update_df.isEmpty():\n",
    "        update_df.writeTo(f\"local.bronze.{prefix}\").overwritePartitions()\n",
    "        logger.info(f\"‚úÖ Atualizados registros existentes na tabela 'local.bronze.{prefix}'.\")\n",
    "\n",
    "    # Manuten√ß√£o na camada bronze\n",
    "    spark.sql(f\"CALL local.system.rewrite_data_files(table => 'local.bronze.{prefix}')\")\n",
    "    logger.info(f\"üßπ Compacta√ß√£o de arquivos executada na tabela 'local.bronze.{prefix}'.\")\n",
    "\n",
    "    # Adiciona arquivos processados √† lista de exclus√£o\n",
    "    files_to_delete.extend(files)\n",
    "\n",
    "# Deleta arquivos processados do bucket ap√≥s todas as opera√ß√µes Spark\n",
    "for file in files_to_delete:\n",
    "    s3.delete_object(Bucket=bucket_name, Key=file)\n",
    "    logger.info(f\"üóëÔ∏è Arquivo deletado do bucket: {file}\")\n",
    "\n",
    "logger.info(\"üöÄ Todas as tabelas foram processadas e os arquivos .csv foram exclu√≠dos com sucesso.\")\n",
    "\n",
    "# Fecha a sess√£o Spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985db3d1-69c0-45d0-9f9c-f7df1d220d18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
